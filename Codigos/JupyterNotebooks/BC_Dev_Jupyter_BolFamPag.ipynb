{"cells": [{"metadata": {}, "cell_type": "markdown", "source": "# ------------------------------ Projeto Cetus ----------------------------------"}, {"metadata": {}, "cell_type": "markdown", "source": "### Assunto: Benef\u00edcios ao Cidad\u00e3o -  Bolsa Fam\u00edlia\n### Defasagem: M-4"}, {"metadata": {"trusted": false}, "cell_type": "code", "source": "# Autor: Bruno Jardim\n# Data: 10/03/2019\n# Descri\u00e7\u00e3o: C\u00f3digo para salvar os dados do portal transpar\u00eancia no datalake (AWS - S3)\n# URL(dados): http://www.portaltransparencia.gov.br/download-de-dados/bolsa-familia-pagamentos\n# URL(Metadados): http://www.portaltransparencia.gov.br/pagina-interna/603397-dicionario-de-dados-bolsa-familia-pagamentos\n# URL(Periodicidade): http://www.portaltransparencia.gov.br/beneficios/consulta?ordenarPor=mesAno&direcao=desc\n# URL(Atualiza\u00e7oes): http://www.portaltransparencia.gov.br/origem-dos-dados\n# URL (Tabelas deste assunto): http://www.portaltransparencia.gov.br/download-de-dados", "execution_count": 18, "outputs": []}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "import requests\nfrom bs4 import BeautifulSoup\nimport re\n\n############# Codigo para buscar data da informacao (Producao) #################### \n\nURL = 'http://www.portaltransparencia.gov.br/beneficios/consulta?ordenarPor=mesAno&direcao=desc'\npage = requests.get(URL)\nsoup = BeautifulSoup(page.content, 'html.parser')\ntableDiv = soup.find_all('div', id=\"datas\")\ndatinfo = re.sub(\"[^\\d\\.]\", \"\", str(tableDiv))[26:]\nprint('Data da Info: ', datinfo)\n\n#Data baixar arquivo\ndatinfo_mes = datinfo[2:-4]\ndatinfo_ano = datinfo[4:]\ndat_get_file = datinfo_ano+datinfo_mes\nprint('Data para baixar arquivo:',dat_get_file)", "execution_count": 1, "outputs": [{"output_type": "stream", "text": "Data da Info:  01122018\nData para baixar arquivo: 201812\n", "name": "stdout"}]}, {"metadata": {"trusted": false}, "cell_type": "code", "source": "ANOMES_INFO = 201801\n\n#http://www.portaltransparencia.gov.br/download-de-dados/bolsa-familia-pagamentos/201801\n\n\nvar_url = 'http://www.portaltransparencia.gov.br/download-de-dados/bolsa-familia-pagamentos/'+str(ANOMES_INFO)\nprint('URL para download dos dados:')\nprint(var_url)\n\nprint('Baixando dados...')\nimport urllib.request\nurllib.request.urlretrieve(var_url, 'dados_bolsafam_' + str(ANOMES_INFO) + '.zip')\n\nprint('Descompactando dados...')\nimport zipfile\nwith zipfile.ZipFile('dados_bolsafam_' + str(ANOMES_INFO) + '.zip',\"r\") as zip_ref:\n    zip_ref.extractall('dados_bolsafam_' + str(ANOMES_INFO))\nprint('Arquivos disponiveis')    ", "execution_count": 30, "outputs": [{"output_type": "stream", "text": "URL para download dos dados:\nhttp://www.portaltransparencia.gov.br/download-de-dados/bolsa-familia-pagamentos/201801\nBaixando dados...\nDescompactando dados...\n", "name": "stdout"}]}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "# Verificar este nome pelo arquivo descompactado \nANOMES_INFO = 201801\nnm_file1 = str(ANOMES_INFO)+'_BolsaFamilia_Pagamentos.csv'\n\n\n#-----------------------  Bolsa Familia ------------------------------\nimport pandas as pd\nimport dask.dataframe as dd\nimport chardet\nwith open('dados_bolsafam_' + str(ANOMES_INFO) +'/' + nm_file1, 'rb') as f:\n    result = chardet.detect(f.readline())  # or readline if the file is large\n    \n    \ndf_00 = pd.read_csv('dados_bolsafam_' + str(ANOMES_INFO) +'/' + nm_file1, encoding=result['encoding'], error_bad_lines=False,sep=';', engine='python')\ndf_00['DT_INFO'] = ANOMES_INFO\n\n\n\n", "execution_count": 3, "outputs": [{"output_type": "error", "ename": "FileNotFoundError", "evalue": "[Errno 2] No such file or directory: 'dados_bolsafam_201801/201801_BolsaFamilia_Pagamentos.csv'", "traceback": ["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m", "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)", "\u001b[0;32m<ipython-input-3-88b37d719df2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataframe\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mdd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mchardet\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'dados_bolsafam_'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mANOMES_INFO\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m'/'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnm_file1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mchardet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# or readline if the file is large\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n", "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'dados_bolsafam_201801/201801_BolsaFamilia_Pagamentos.csv'"]}]}, {"metadata": {"trusted": false}, "cell_type": "code", "source": "df_00.describe()", "execution_count": 42, "outputs": [{"output_type": "execute_result", "execution_count": 42, "data": {"text/plain": "Dask DataFrame Structure:\n              Ano/M\u00eas Refer\u00eancia Ano/M\u00eas Compet\u00eancia C\u00f3digo Munic\u00edpio SIAFI NIS Benefici\u00e1rio DT_INFO\nnpartitions=1                                                                                       \n                           int64               int64                  int64            int64   int64\n                             ...                 ...                    ...              ...     ...\nDask Name: describe, 1083 tasks", "text/html": "<div><strong>Dask DataFrame Structure:</strong></div>\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Ano/M\u00eas Refer\u00eancia</th>\n      <th>Ano/M\u00eas Compet\u00eancia</th>\n      <th>C\u00f3digo Munic\u00edpio SIAFI</th>\n      <th>NIS Benefici\u00e1rio</th>\n      <th>DT_INFO</th>\n    </tr>\n    <tr>\n      <th>npartitions=1</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th></th>\n      <td>int64</td>\n      <td>int64</td>\n      <td>int64</td>\n      <td>int64</td>\n      <td>int64</td>\n    </tr>\n    <tr>\n      <th></th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n<div>Dask Name: describe, 1083 tasks</div>"}, "metadata": {}}]}, {"metadata": {"trusted": false}, "cell_type": "code", "source": "", "execution_count": null, "outputs": []}, {"metadata": {"trusted": false}, "cell_type": "code", "source": "", "execution_count": null, "outputs": []}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "def CetusLakeBeneficiosCidadaoBolsaFamilia(dataproc,ANOMES_INFO,exec_lake = 'prod'):\n    \n    #---- Pagina de Extracao -----------\n    # http://www.portaltransparencia.gov.br/download-de-dados/bolsa-familia-pagamentos\n    \n    #---- Metadados do Arquivo ---------\n    # http://www.portaltransparencia.gov.br/pagina-interna/603397-dicionario-de-dados-bolsa-familia-pagamentos\n    \n    \n    # ----- Pegando a Data da Informacao e Gravando na Tabela -------------------\n    import requests\n    from bs4 import BeautifulSoup\n    import re\n    import dask.dataframe as dd\n    \n    if exec_lake == 'prod':\n        print('CETUS --> Executando em Producao')\n        extr = 'P'\n\n        # Utilizado para producao (execucao semanal ou mensal)\n        URL = 'http://www.portaltransparencia.gov.br/beneficios/consulta?ordenarPor=mesAno&direcao=desc'\n        page = requests.get(URL)\n        soup = BeautifulSoup(page.content, 'html.parser')\n        tableDiv = soup.find_all('div', id=\"datas\")\n        datinfo = re.sub(\"[^\\d\\.]\", \"\", str(tableDiv))[26:]\n        print('Data da Info: ', datinfo)\n        \n        #Data baixar arquivo\n        datinfo_mes = datinfo[2:-4]\n        datinfo_ano = datinfo[4:]\n        ANOMES_INFO = datinfo_ano+datinfo_mes\n        print('Data para baixar arquivo:',ANOMES_INFO)\n        # ----------------------------------------------------------------------------\n    else:\n        print('CETUS --> Executando Carga Historica')\n        # Formato que pegamos no site quando no modo producao (DDMMAAAA)\n        datinfo = str(ANOMES_INFO)\n        extr = 'H'\n \n   \n    var_url = 'http://www.portaltransparencia.gov.br/download-de-dados/bolsa-familia-pagamentos/'+str(ANOMES_INFO)\n    print('URL para download dos dados:')\n    print(var_url)\n\n    print('Baixando dados...')\n    import urllib.request\n    urllib.request.urlretrieve(var_url, 'dados_bolsafam_' + str(ANOMES_INFO) + '.zip')\n\n    print('Descompactando dados...')\n    import zipfile\n    with zipfile.ZipFile('dados_bolsafam_' + str(ANOMES_INFO) + '.zip',\"r\") as zip_ref:\n        zip_ref.extractall('dados_bolsafam_' + str(ANOMES_INFO))\n    print('Arquivos disponiveis') \n\n    #-----------------------  Bolsa Familia ------------------------------\n    # Verificar este nome pelo arquivo descompactado \n    nm_file1 = str(ANOMES_INFO)+'_BolsaFamilia_Pagamentos.csv'\n\n    #-----------------------  Bolsa Familia ------------------------------\n    import pandas as pd\n    import chardet\n    with open('dados_bolsafam_' + str(ANOMES_INFO) +'/' + nm_file1, 'rb') as f:\n        result = chardet.detect(f.readline())  # or readline if the file is large\n    df_00 = dd.read_csv('dados_bolsafam_' + str(ANOMES_INFO) +'/' + nm_file1, encoding=result['encoding'], error_bad_lines=False,sep=';', engine='python')\n    encode_df = result['encoding']\n    df_00['DT_INFO'] = ANOMES_INFO\n    df_00['ID_PROC'] = extr\n    return df_00,encode_df,datinfo\n\n\ndef CetusSalvaCSVS3(dataframe,nm_s3_file,s3_path,encode_df):\n\n    import s3fs\n    S3fs = s3fs.S3FileSystem()\n\n    # Nome do arquivo a ser salvo no S3\n    #nm_s3_file = 'OrcamentoDespesas_'+str(dtref)+'.csv'\n\n    # Caminho no lake (S3)\n    #s3_path = 'projeto-cetus/datalake/OrcamentoDespesas/dados/'\n\n    bytes_to_write = dataframe.to_csv(sep = ',',header=True, index=False, index_label=None,encoding=encode_df)\n    with S3fs.open(s3_path+nm_s3_file, 'wb') as f:\n        f.write(bytes_to_write)\n\ndef CetusRefVecDays(inicio,fim):\n     import datetime\n     start = datetime.datetime.strptime(inicio, \"%Y%m%d\")\n     end = datetime.datetime.strptime(fim, \"%Y%m%d\")\n     date_generated = [start + datetime.timedelta(days=x) for x in range(0, (end-start).days)]\n     #print('Data inicial: ',start.strftime(\"%Y%m%d\") ) \n     #print('Data final: ',end.strftime(\"%Y%m%d\") ) \n     #print('Quantidade de Parti\u00e7\u00f5es: ',len(date_generated)) \n     return date_generated\n\n", "execution_count": 4, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "### Carga Hist\u00f3rica"}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "vetor_safras_aux = CetusRefVecDays('20170101','20181231') \n#s3_path = 'projeto-bigdata-cetus/datalake/xxxxxxxxxxxx/'\n\nanomes = []\nfor data_ref in vetor_safras_aux:    \n    anomes.append(data_ref.strftime(\"%Y%m\"))\n    \nvetor_safras = list(dict.fromkeys(anomes))\n\n\nimport datetime\nnow = datetime.datetime.now() - datetime.timedelta(0,0,0,0,3)\nanomesdia = now.strftime(\"%Y%m%d\")\ndiamesano = now.strftime(\"%d%m%Y\")\nanoref = now.strftime(\"%Y\")\n\n\nfor anomes in vetor_safras:\n    print('Cetus - Carga Hist\u00f3rica Ref ---->', anomes)\n    dados,encode_df,datinfo = CetusLakeBeneficiosCidadaoBolsaFamilia(diamesano,anomes,exec_lake = 'Hist')\n    nm_s3_file = 'BC_Lake_BolFamPag_'+str(datinfo)+'.csv'\n    s3_path = 'projeto-bigdata-cetus/datalake/BeneficiosCidadaos/'\n    CetusSalvaCSVS3(dados,nm_s3_file,s3_path)  ", "execution_count": null, "outputs": [{"output_type": "stream", "text": "Cetus - Carga Hist\u00f3rica Ref ----> 201701\nCETUS --> Executando Carga Historica\nURL para download dos dados:\nhttp://www.portaltransparencia.gov.br/download-de-dados/bolsa-familia-pagamentos/201701\nBaixando dados...\n", "name": "stdout"}]}, {"metadata": {"trusted": false}, "cell_type": "code", "source": "", "execution_count": null, "outputs": []}], "metadata": {"kernelspec": {"name": "python3", "display_name": "Python 3", "language": "python"}, "language_info": {"name": "python", "version": "3.6.6", "mimetype": "text/x-python", "codemirror_mode": {"name": "ipython", "version": 3}, "pygments_lexer": "ipython3", "nbconvert_exporter": "python", "file_extension": ".py"}}, "nbformat": 4, "nbformat_minor": 2}